# Speech synthesis

Speech synthesis is the artificial production of human speech. A computer system used for this purpose is called a speech computer or speech synthesizer, and can be implemented in software or hardware products. A text-to-speech (TTS) system converts normal language text into speech; other systems render symbolic linguistic representations like phonetic transcriptions into speech. The reverse process is speech recognition.

Read more on [Wikipedia](https://en.wikipedia.org/wiki/Speech_synthesis).

#### Examples

##### Using AI
- [Coqui](https://coqui.ai): A startup providing open speech tech for everyone ⭐
- [Mimic 2](https://github.com/MycroftAI/mimic2): Text to Speech engine based on the Tacotron architecture
- [Mimic 3](https://github.com/MycroftAI/mimic3): A fast local neural text to speech engine for Mycroft ⭐
- [Sonantic](https://www.sonantic.io): Deliver compelling, lifelike performances with fully expressive AI-generated voices
- [TorToiSe](https://github.com/neonbjb/tortoise-tts): A multi-voice TTS system trained with an emphasis on quality

##### Not using AI
- [eSpeak NG](https://github.com/espeak-ng/espeak-ng): An open source speech synthesizer
- [Festival](https://www.cstr.ed.ac.uk/projects/festival): Offers a general framework for building speech synthesis systems
    - [Flite](https://github.com/festvox/flite): A small fast portable speech synthesis system
        - [Mimic 1](https://github.com/MycroftAI/mimic1): Mycroft's TTS engine, based on CMU's Flite (Festival Lite)
